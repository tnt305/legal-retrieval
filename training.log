2024-11-01 07:31:28,577 - INFO - Using device: cuda
2024-11-01 07:31:28,577 - INFO - Loading datasets...
2024-11-01 07:31:30,465 - INFO - Loaded 261772 corpus documents, 119456 queries
2024-11-01 07:31:30,465 - INFO - Preparing training dataset...
2024-11-01 07:31:32,993 - INFO - Setting up model and tokenizer...
2024-11-01 07:31:39,584 - INFO - Use pytorch device_name: cuda
2024-11-01 07:31:49,303 - INFO - Creating evaluators...
2024-11-01 07:31:49,911 - INFO - Setting up trainer...
2024-11-01 07:31:58,924 - WARNING - Currently using DataParallel (DP) for multi-gpu training, while DistributedDataParallel (DDP) is recommended for faster training. See https://sbert.net/docs/sentence_transformer/training/distributed.html for more information.
2024-11-01 07:32:08,061 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2024-11-01 07:32:08,974 - INFO - Starting training...
2024-11-01 07:32:23,839 - ERROR - Training failed: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.75 GiB total capacity; 9.78 GiB already allocated; 7.56 MiB free; 10.01 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2024-11-01 07:38:49,202 - INFO - Using device: cuda
2024-11-01 07:38:49,202 - INFO - Loading datasets...
2024-11-01 07:38:51,084 - INFO - Loaded 261772 corpus documents, 119456 queries
2024-11-01 07:38:51,084 - INFO - Preparing training dataset...
2024-11-01 07:38:53,864 - INFO - Setting up model and tokenizer...
2024-11-01 07:39:14,489 - INFO - Use pytorch device_name: cuda
2024-11-01 07:39:24,205 - INFO - Creating evaluators...
2024-11-01 07:39:24,879 - INFO - Setting up trainer...
2024-11-01 07:39:33,916 - WARNING - Currently using DataParallel (DP) for multi-gpu training, while DistributedDataParallel (DDP) is recommended for faster training. See https://sbert.net/docs/sentence_transformer/training/distributed.html for more information.
2024-11-01 07:39:43,169 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2024-11-01 07:39:45,880 - INFO - Starting training...
2024-11-01 07:39:58,499 - ERROR - Training failed: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`
2024-11-01 07:42:38,509 - INFO - Using device: cuda
2024-11-01 07:42:38,511 - INFO - Loading datasets...
2024-11-01 07:42:40,544 - INFO - Loaded 261772 corpus documents, 119456 queries
2024-11-01 07:42:40,544 - INFO - Preparing training dataset...
2024-11-01 07:42:43,670 - INFO - Setting up model and tokenizer...
2024-11-01 07:42:55,370 - INFO - Use pytorch device_name: cuda
2024-11-01 07:43:14,899 - INFO - Creating evaluators...
2024-11-01 07:43:15,515 - INFO - Setting up trainer...
2024-11-01 07:43:24,518 - WARNING - Currently using DataParallel (DP) for multi-gpu training, while DistributedDataParallel (DDP) is recommended for faster training. See https://sbert.net/docs/sentence_transformer/training/distributed.html for more information.
2024-11-01 07:43:33,656 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2024-11-01 07:43:36,782 - INFO - Starting training...
2024-11-01 07:43:49,488 - ERROR - Training failed: Caught RuntimeError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/home/thiendc/projects/.thienenv/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py", line 64, in _worker
    output = module(*input, **kwargs)
  File "/home/thiendc/projects/.thienenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/thiendc/projects/.thienenv/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py", line 683, in forward
    return super().forward(input)
  File "/home/thiendc/projects/.thienenv/lib/python3.10/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/thiendc/projects/.thienenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/thiendc/projects/.thienenv/lib/python3.10/site-packages/sentence_transformers/models/Transformer.py", line 350, in forward
    output_states = self.auto_model(**trans_features, **kwargs, return_dict=False)
  File "/home/thiendc/projects/.thienenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/thiendc/projects/.thienenv/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py", line 976, in forward
    encoder_outputs = self.encoder(
  File "/home/thiendc/projects/.thienenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/thiendc/projects/.thienenv/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py", line 620, in forward
    layer_outputs = self._gradient_checkpointing_func(
  File "/home/thiendc/projects/.thienenv/lib/python3.10/site-packages/torch/utils/checkpoint.py", line 249, in checkpoint
    return CheckpointFunction.apply(function, preserve, *args)
  File "/home/thiendc/projects/.thienenv/lib/python3.10/site-packages/torch/autograd/function.py", line 506, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/home/thiendc/projects/.thienenv/lib/python3.10/site-packages/torch/utils/checkpoint.py", line 107, in forward
    outputs = run_function(*args)
  File "/home/thiendc/projects/.thienenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/thiendc/projects/.thienenv/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py", line 520, in forward
    self_attention_outputs = self.attention(
  File "/home/thiendc/projects/.thienenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/thiendc/projects/.thienenv/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py", line 447, in forward
    self_outputs = self.self(
  File "/home/thiendc/projects/.thienenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/thiendc/projects/.thienenv/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py", line 233, in forward
    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))
RuntimeError: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`

2024-11-01 13:38:06,801 - INFO - Added key: store_based_barrier_key:1 to store for rank: 0
2024-11-01 13:38:06,802 - INFO - Added key: store_based_barrier_key:1 to store for rank: 3
2024-11-01 13:38:06,803 - INFO - Added key: store_based_barrier_key:1 to store for rank: 2
2024-11-01 13:38:06,805 - INFO - Added key: store_based_barrier_key:1 to store for rank: 1
2024-11-01 13:38:06,806 - INFO - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-11-01 13:38:06,813 - INFO - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-11-01 13:38:06,813 - INFO - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-11-01 13:38:06,814 - INFO - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-11-01 13:38:42,406 - INFO - Using device: cuda:3
2024-11-01 13:38:42,407 - INFO - Loading datasets...
2024-11-01 13:38:42,409 - INFO - Using device: cuda:2
2024-11-01 13:38:42,409 - INFO - Loading datasets...
2024-11-01 13:38:42,452 - INFO - Using device: cuda:0
2024-11-01 13:38:42,454 - INFO - Loading datasets...
2024-11-01 13:38:42,453 - INFO - Using device: cuda:1
2024-11-01 13:38:42,454 - INFO - Loading datasets...
2024-11-01 13:38:44,378 - INFO - Loaded 261772 corpus documents, 119456 queries
2024-11-01 13:38:44,378 - INFO - Preparing training dataset...
2024-11-01 13:38:44,417 - INFO - Loaded 261772 corpus documents, 119456 queries
2024-11-01 13:38:44,417 - INFO - Preparing training dataset...
2024-11-01 13:38:44,563 - INFO - Loaded 261772 corpus documents, 119456 queries
2024-11-01 13:38:44,564 - INFO - Preparing training dataset...
2024-11-01 13:38:44,583 - INFO - Loaded 261772 corpus documents, 119456 queries
2024-11-01 13:38:44,583 - INFO - Preparing training dataset...
2024-11-01 13:38:47,134 - INFO - Setting up model and tokenizer...
2024-11-01 13:38:47,252 - INFO - Setting up model and tokenizer...
2024-11-01 13:38:47,377 - INFO - Setting up model and tokenizer...
2024-11-01 13:38:47,451 - INFO - Setting up model and tokenizer...
2024-11-01 13:38:49,713 - INFO - Use pytorch device_name: cuda
2024-11-01 13:38:49,735 - INFO - Use pytorch device_name: cuda
2024-11-01 13:38:49,941 - INFO - Use pytorch device_name: cuda
2024-11-01 13:38:50,125 - INFO - Use pytorch device_name: cuda
2024-11-01 13:38:51,149 - INFO - Creating evaluators...
2024-11-01 13:38:51,151 - INFO - Creating evaluators...
2024-11-01 13:38:51,151 - INFO - Creating evaluators...
2024-11-01 13:38:51,158 - INFO - Creating evaluators...
2024-11-01 13:38:51,626 - INFO - Setting up trainer...
2024-11-01 13:38:51,684 - INFO - Setting up trainer...
2024-11-01 13:38:51,758 - INFO - Setting up trainer...
2024-11-01 13:38:51,854 - INFO - Setting up trainer...
2024-11-01 13:39:36,587 - WARNING - When using DistributedDataParallel (DDP), it is recommended to set `dataloader_drop_last=True` to avoid hanging issues with an uneven last batch. Setting `dataloader_drop_last=True`.
2024-11-01 13:39:36,587 - WARNING - When using DistributedDataParallel (DDP), it is recommended to set `dataloader_drop_last=True` to avoid hanging issues with an uneven last batch. Setting `dataloader_drop_last=True`.
2024-11-01 13:39:36,588 - WARNING - When using DistributedDataParallel (DDP), it is recommended to set `dataloader_drop_last=True` to avoid hanging issues with an uneven last batch. Setting `dataloader_drop_last=True`.
2024-11-01 13:39:36,590 - WARNING - When using DistributedDataParallel (DDP), it is recommended to set `dataloader_drop_last=True` to avoid hanging issues with an uneven last batch. Setting `dataloader_drop_last=True`.
2024-11-01 13:40:21,036 - ERROR - Training failed: 'DistributedDataParallel' object has no attribute 'tokenizer'
2024-11-01 13:40:21,045 - ERROR - Training failed: 'DistributedDataParallel' object has no attribute 'tokenizer'
2024-11-01 13:40:21,047 - ERROR - Training failed: 'DistributedDataParallel' object has no attribute 'tokenizer'
2024-11-01 13:40:21,054 - ERROR - Training failed: 'DistributedDataParallel' object has no attribute 'tokenizer'
2024-11-01 14:15:03,017 - INFO - Added key: store_based_barrier_key:1 to store for rank: 1
2024-11-01 14:15:03,018 - INFO - Added key: store_based_barrier_key:1 to store for rank: 0
2024-11-01 14:15:03,023 - INFO - Added key: store_based_barrier_key:1 to store for rank: 3
2024-11-01 14:15:03,024 - INFO - Added key: store_based_barrier_key:1 to store for rank: 2
2024-11-01 14:15:03,025 - INFO - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-11-01 14:15:03,028 - INFO - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-11-01 14:15:03,029 - INFO - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-11-01 14:15:03,034 - INFO - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-11-01 14:15:53,666 - INFO - Using device: cuda:0
2024-11-01 14:15:53,667 - INFO - Loading datasets...
2024-11-01 14:15:53,667 - INFO - Using device: cuda:3
2024-11-01 14:15:53,668 - INFO - Loading datasets...
2024-11-01 14:15:53,670 - INFO - Using device: cuda:1
2024-11-01 14:15:53,670 - INFO - Loading datasets...
2024-11-01 14:15:53,671 - INFO - Using device: cuda:2
2024-11-01 14:15:53,672 - INFO - Loading datasets...
2024-11-01 14:15:55,634 - INFO - Loaded 261772 corpus documents, 119456 queries
2024-11-01 14:15:55,635 - INFO - Preparing training dataset...
2024-11-01 14:15:55,684 - INFO - Loaded 261772 corpus documents, 119456 queries
2024-11-01 14:15:55,684 - INFO - Preparing training dataset...
2024-11-01 14:15:55,702 - INFO - Loaded 261772 corpus documents, 119456 queries
2024-11-01 14:15:55,702 - INFO - Preparing training dataset...
2024-11-01 14:15:55,794 - INFO - Loaded 261772 corpus documents, 119456 queries
2024-11-01 14:15:55,794 - INFO - Preparing training dataset...
2024-11-01 14:15:58,424 - INFO - Setting up model and tokenizer...
2024-11-01 14:15:58,485 - INFO - Setting up model and tokenizer...
2024-11-01 14:15:58,489 - INFO - Setting up model and tokenizer...
2024-11-01 14:15:58,660 - INFO - Setting up model and tokenizer...
2024-11-01 14:16:00,889 - INFO - Use pytorch device_name: cuda
2024-11-01 14:16:00,953 - INFO - Use pytorch device_name: cuda
2024-11-01 14:16:01,459 - ERROR - Training failed: 'SentenceTransformer' object has no attribute 'transformer'
2024-11-01 14:16:01,468 - INFO - Use pytorch device_name: cuda
2024-11-01 14:16:01,580 - INFO - Use pytorch device_name: cuda
2024-11-01 14:16:01,765 - ERROR - Training failed: 'SentenceTransformer' object has no attribute 'transformer'
2024-11-01 14:16:02,076 - ERROR - Training failed: 'SentenceTransformer' object has no attribute 'transformer'
2024-11-01 14:16:02,107 - ERROR - Training failed: 'SentenceTransformer' object has no attribute 'transformer'
2024-11-01 14:20:08,765 - INFO - Added key: store_based_barrier_key:1 to store for rank: 2
2024-11-01 14:20:08,782 - INFO - Added key: store_based_barrier_key:1 to store for rank: 1
2024-11-01 14:20:08,785 - INFO - Added key: store_based_barrier_key:1 to store for rank: 3
2024-11-01 14:20:08,785 - INFO - Added key: store_based_barrier_key:1 to store for rank: 0
2024-11-01 14:20:08,786 - INFO - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-11-01 14:20:08,786 - INFO - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-11-01 14:20:08,787 - INFO - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-11-01 14:20:08,793 - INFO - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-11-01 14:20:44,385 - INFO - Using device: cuda:2
2024-11-01 14:20:44,385 - INFO - Loading datasets...
2024-11-01 14:20:44,419 - INFO - Using device: cuda:1
2024-11-01 14:20:44,419 - INFO - Loading datasets...
2024-11-01 14:20:44,426 - INFO - Using device: cuda:3
2024-11-01 14:20:44,427 - INFO - Loading datasets...
2024-11-01 14:20:44,430 - INFO - Using device: cuda:0
2024-11-01 14:20:44,431 - INFO - Loading datasets...
2024-11-01 14:20:46,324 - INFO - Loaded 261772 corpus documents, 119456 queries
2024-11-01 14:20:46,324 - INFO - Preparing training dataset...
2024-11-01 14:20:46,395 - INFO - Loaded 261772 corpus documents, 119456 queries
2024-11-01 14:20:46,395 - INFO - Preparing training dataset...
2024-11-01 14:20:46,435 - INFO - Loaded 261772 corpus documents, 119456 queries
2024-11-01 14:20:46,435 - INFO - Preparing training dataset...
2024-11-01 14:20:46,464 - INFO - Loaded 261772 corpus documents, 119456 queries
2024-11-01 14:20:46,464 - INFO - Preparing training dataset...
2024-11-01 14:20:49,080 - INFO - Setting up model and tokenizer...
2024-11-01 14:20:49,179 - INFO - Setting up model and tokenizer...
2024-11-01 14:20:49,311 - INFO - Setting up model and tokenizer...
2024-11-01 14:20:49,331 - INFO - Setting up model and tokenizer...
2024-11-01 14:20:51,633 - INFO - Use pytorch device_name: cuda
2024-11-01 14:20:51,650 - INFO - Use pytorch device_name: cuda
2024-11-01 14:20:51,695 - INFO - Use pytorch device_name: cuda
2024-11-01 14:20:52,222 - INFO - Use pytorch device_name: cuda
2024-11-01 14:20:53,041 - INFO - Creating evaluators...
2024-11-01 14:20:53,043 - INFO - Creating evaluators...
2024-11-01 14:20:53,046 - INFO - Creating evaluators...
2024-11-01 14:20:53,048 - INFO - Creating evaluators...
2024-11-01 14:20:53,472 - INFO - Setting up trainer...
2024-11-01 14:20:53,504 - INFO - Setting up trainer...
2024-11-01 14:20:53,676 - INFO - Setting up trainer...
2024-11-01 14:20:53,712 - INFO - Setting up trainer...
2024-11-01 14:21:30,375 - WARNING - When using DistributedDataParallel (DDP), it is recommended to set `dataloader_drop_last=True` to avoid hanging issues with an uneven last batch. Setting `dataloader_drop_last=True`.
2024-11-01 14:21:30,381 - WARNING - When using DistributedDataParallel (DDP), it is recommended to set `dataloader_drop_last=True` to avoid hanging issues with an uneven last batch. Setting `dataloader_drop_last=True`.
2024-11-01 14:21:30,383 - WARNING - When using DistributedDataParallel (DDP), it is recommended to set `dataloader_drop_last=True` to avoid hanging issues with an uneven last batch. Setting `dataloader_drop_last=True`.
2024-11-01 14:21:30,391 - WARNING - When using DistributedDataParallel (DDP), it is recommended to set `dataloader_drop_last=True` to avoid hanging issues with an uneven last batch. Setting `dataloader_drop_last=True`.
2024-11-01 14:22:05,978 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2024-11-01 14:22:08,492 - INFO - Starting training...
2024-11-01 14:22:08,680 - INFO - Starting training...
2024-11-01 14:22:08,712 - INFO - Starting training...
2024-11-01 14:22:08,715 - ERROR - Training failed: 'DistributedDataParallel' object has no attribute 'gradient_checkpointing_enable'
2024-11-01 14:22:08,764 - INFO - Starting training...
2024-11-01 14:22:09,166 - ERROR - Training failed: 'DistributedDataParallel' object has no attribute 'gradient_checkpointing_enable'
2024-11-01 14:22:09,211 - ERROR - Training failed: 'DistributedDataParallel' object has no attribute 'gradient_checkpointing_enable'
2024-11-01 14:22:09,220 - ERROR - Training failed: 'DistributedDataParallel' object has no attribute 'gradient_checkpointing_enable'
2024-11-01 14:40:53,379 - INFO - Using device: cuda
2024-11-01 14:40:53,379 - INFO - Loading datasets...
2024-11-01 14:40:55,187 - INFO - Loaded 261772 corpus documents, 119456 queries
2024-11-01 14:40:55,187 - INFO - Preparing training dataset...
2024-11-01 14:40:57,631 - INFO - Setting up model and tokenizer...
2024-11-01 14:40:59,891 - INFO - Use pytorch device_name: cuda
2024-11-01 14:41:09,541 - INFO - Creating evaluators...
2024-11-01 14:41:10,105 - INFO - Setting up trainer...
2024-11-01 14:41:19,135 - WARNING - Currently using DataParallel (DP) for multi-gpu training, while DistributedDataParallel (DDP) is recommended for faster training. See https://sbert.net/docs/sentence_transformer/training/distributed.html for more information.
2024-11-01 14:41:28,274 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2024-11-01 14:41:30,993 - INFO - Starting training...
2024-11-01 14:41:44,166 - ERROR - Training failed: CUDA out of memory. Tried to allocate 206.00 MiB (GPU 0; 10.75 GiB total capacity; 2.21 GiB already allocated; 25.56 MiB free; 2.35 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2024-11-01 14:46:44,300 - INFO - Using device: cuda
2024-11-01 14:46:44,300 - INFO - Loading datasets...
2024-11-01 14:46:46,212 - INFO - Loaded 261772 corpus documents, 119456 queries
2024-11-01 14:46:46,213 - INFO - Preparing training dataset...
2024-11-01 14:46:48,810 - INFO - Setting up model and tokenizer...
2024-11-01 14:46:51,012 - INFO - Use pytorch device_name: cuda
2024-11-01 14:47:00,702 - INFO - Creating evaluators...
2024-11-01 14:47:01,279 - INFO - Setting up trainer...
2024-11-01 14:47:10,304 - WARNING - Currently using DataParallel (DP) for multi-gpu training, while DistributedDataParallel (DDP) is recommended for faster training. See https://sbert.net/docs/sentence_transformer/training/distributed.html for more information.
2024-11-01 14:47:19,406 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2024-11-01 14:47:22,051 - INFO - Starting training...
2024-11-01 14:58:34,586 - INFO - Information Retrieval Evaluation of the model on the dim_768 dataset (truncated to 768):
2024-11-01 15:40:33,783 - INFO - Using device: cuda
2024-11-01 15:40:33,784 - INFO - Loading datasets...
2024-11-01 15:40:33,792 - INFO - Using device: cuda
2024-11-01 15:40:33,793 - INFO - Loading datasets...
2024-11-01 15:40:33,793 - INFO - Using device: cuda
2024-11-01 15:40:33,794 - INFO - Loading datasets...
2024-11-01 15:40:33,794 - INFO - Using device: cuda
2024-11-01 15:40:33,795 - INFO - Loading datasets...
2024-11-01 15:40:35,711 - INFO - Loaded 261772 corpus documents, 119456 queries
2024-11-01 15:40:35,711 - INFO - Preparing training dataset...
2024-11-01 15:40:35,734 - INFO - Loaded 261772 corpus documents, 119456 queries
2024-11-01 15:40:35,735 - INFO - Preparing training dataset...
2024-11-01 15:40:35,743 - INFO - Loaded 261772 corpus documents, 119456 queries
2024-11-01 15:40:35,743 - INFO - Preparing training dataset...
2024-11-01 15:40:35,792 - INFO - Loaded 261772 corpus documents, 119456 queries
2024-11-01 15:40:35,792 - INFO - Preparing training dataset...
2024-11-01 15:40:38,544 - INFO - Setting up model and tokenizer...
2024-11-01 15:40:38,549 - INFO - Setting up model and tokenizer...
2024-11-01 15:40:38,672 - INFO - Setting up model and tokenizer...
2024-11-01 15:40:38,674 - INFO - Setting up model and tokenizer...
2024-11-01 15:40:41,001 - INFO - Use pytorch device_name: cuda
2024-11-01 15:40:41,189 - INFO - Use pytorch device_name: cuda
2024-11-01 15:40:41,629 - INFO - Use pytorch device_name: cuda
2024-11-01 15:40:41,743 - INFO - Use pytorch device_name: cuda
2024-11-01 15:42:11,610 - INFO - Creating evaluators...
2024-11-01 15:42:11,661 - INFO - Creating evaluators...
2024-11-01 15:42:11,670 - INFO - Creating evaluators...
2024-11-01 15:42:12,294 - INFO - Setting up trainer...
2024-11-01 15:42:12,298 - INFO - Added key: store_based_barrier_key:1 to store for rank: 1
2024-11-01 15:42:12,364 - INFO - Setting up trainer...
2024-11-01 15:42:12,368 - INFO - Added key: store_based_barrier_key:1 to store for rank: 3
2024-11-01 15:42:12,387 - INFO - Setting up trainer...
2024-11-01 15:42:12,391 - INFO - Added key: store_based_barrier_key:1 to store for rank: 2
2024-11-01 15:42:22,306 - INFO - Waiting in store based barrier to initialize process group for rank: 1, key: store_based_barrier_key:1 (world_size=4, worker_count=3, timeout=0:30:00)
2024-11-01 15:42:22,372 - INFO - Waiting in store based barrier to initialize process group for rank: 3, key: store_based_barrier_key:1 (world_size=4, worker_count=3, timeout=0:30:00)
2024-11-01 15:42:22,393 - INFO - Waiting in store based barrier to initialize process group for rank: 2, key: store_based_barrier_key:1 (world_size=4, worker_count=3, timeout=0:30:00)
2024-11-01 15:42:29,245 - INFO - Creating evaluators...
2024-11-01 15:42:29,927 - INFO - Setting up trainer...
2024-11-01 15:42:29,931 - INFO - Added key: store_based_barrier_key:1 to store for rank: 0
2024-11-01 15:42:29,931 - INFO - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-11-01 15:42:29,932 - INFO - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-11-01 15:42:29,939 - INFO - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-11-01 15:42:29,939 - INFO - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-11-01 15:43:29,662 - WARNING - When using DistributedDataParallel (DDP), it is recommended to set `dataloader_drop_last=True` to avoid hanging issues with an uneven last batch. Setting `dataloader_drop_last=True`.
2024-11-01 15:43:29,666 - WARNING - When using DistributedDataParallel (DDP), it is recommended to set `dataloader_drop_last=True` to avoid hanging issues with an uneven last batch. Setting `dataloader_drop_last=True`.
2024-11-01 15:43:29,678 - WARNING - When using DistributedDataParallel (DDP), it is recommended to set `dataloader_drop_last=True` to avoid hanging issues with an uneven last batch. Setting `dataloader_drop_last=True`.
2024-11-01 15:43:29,677 - WARNING - When using DistributedDataParallel (DDP), it is recommended to set `dataloader_drop_last=True` to avoid hanging issues with an uneven last batch. Setting `dataloader_drop_last=True`.
2024-11-01 15:44:05,367 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2024-11-01 15:44:08,067 - INFO - Starting training...
2024-11-01 15:44:08,507 - INFO - Starting training...
2024-11-01 15:44:08,556 - INFO - Starting training...
2024-11-01 15:44:08,733 - INFO - Starting training...
2024-11-01 15:44:20,426 - ERROR - Training failed: Expected to mark a variable ready only once. This error is caused by one of the following reasons: 1) Use of a module parameter outside the `forward` function. Please make sure model parameters are not shared across multiple concurrent forward-backward passes. or try to use _set_static_graph() as a workaround if this module graph does not change during training loop.2) Reused parameters in multiple reentrant backward passes. For example, if you use multiple `checkpoint` functions to wrap the same part of your model, it would result in the same set of parameters been used by different reentrant backward passes multiple times, and hence marking a variable ready multiple times. DDP does not support such use cases in default. You can try to use _set_static_graph() as a workaround if your module graph does not change over iterations.
Parameter at index 195 has been marked as ready twice. This means that multiple autograd engine  hooks have fired for this particular parameter during this iteration. You can set the environment variable TORCH_DISTRIBUTED_DEBUG to either INFO or DETAIL to print parameter names for further debugging.
2024-11-01 15:44:20,609 - ERROR - Training failed: Expected to mark a variable ready only once. This error is caused by one of the following reasons: 1) Use of a module parameter outside the `forward` function. Please make sure model parameters are not shared across multiple concurrent forward-backward passes. or try to use _set_static_graph() as a workaround if this module graph does not change during training loop.2) Reused parameters in multiple reentrant backward passes. For example, if you use multiple `checkpoint` functions to wrap the same part of your model, it would result in the same set of parameters been used by different reentrant backward passes multiple times, and hence marking a variable ready multiple times. DDP does not support such use cases in default. You can try to use _set_static_graph() as a workaround if your module graph does not change over iterations.
Parameter at index 195 has been marked as ready twice. This means that multiple autograd engine  hooks have fired for this particular parameter during this iteration. You can set the environment variable TORCH_DISTRIBUTED_DEBUG to either INFO or DETAIL to print parameter names for further debugging.
2024-11-01 15:44:21,599 - ERROR - Training failed: Expected to mark a variable ready only once. This error is caused by one of the following reasons: 1) Use of a module parameter outside the `forward` function. Please make sure model parameters are not shared across multiple concurrent forward-backward passes. or try to use _set_static_graph() as a workaround if this module graph does not change during training loop.2) Reused parameters in multiple reentrant backward passes. For example, if you use multiple `checkpoint` functions to wrap the same part of your model, it would result in the same set of parameters been used by different reentrant backward passes multiple times, and hence marking a variable ready multiple times. DDP does not support such use cases in default. You can try to use _set_static_graph() as a workaround if your module graph does not change over iterations.
Parameter at index 195 has been marked as ready twice. This means that multiple autograd engine  hooks have fired for this particular parameter during this iteration. You can set the environment variable TORCH_DISTRIBUTED_DEBUG to either INFO or DETAIL to print parameter names for further debugging.
2024-11-01 16:30:16,805 - INFO - Using device: cuda
2024-11-01 16:30:16,805 - INFO - Loading datasets...
2024-11-01 16:30:16,810 - INFO - Using device: cuda
2024-11-01 16:30:16,811 - INFO - Loading datasets...
2024-11-01 16:30:16,815 - INFO - Using device: cuda
2024-11-01 16:30:16,816 - INFO - Loading datasets...
2024-11-01 16:30:16,816 - INFO - Using device: cuda
2024-11-01 16:30:16,817 - INFO - Loading datasets...
2024-11-01 16:30:18,768 - INFO - Loaded 261772 corpus documents, 119456 queries
2024-11-01 16:30:18,768 - INFO - Preparing training dataset...
2024-11-01 16:30:18,790 - INFO - Loaded 261772 corpus documents, 119456 queries
2024-11-01 16:30:18,790 - INFO - Preparing training dataset...
2024-11-01 16:30:18,807 - INFO - Loaded 261772 corpus documents, 119456 queries
2024-11-01 16:30:18,807 - INFO - Preparing training dataset...
2024-11-01 16:30:18,814 - INFO - Loaded 261772 corpus documents, 119456 queries
2024-11-01 16:30:18,814 - INFO - Preparing training dataset...
2024-11-01 16:30:21,596 - INFO - Setting up model and tokenizer...
2024-11-01 16:30:21,604 - INFO - Setting up model and tokenizer...
2024-11-01 16:30:21,647 - INFO - Setting up model and tokenizer...
2024-11-01 16:30:21,688 - INFO - Setting up model and tokenizer...
2024-11-01 16:30:22,995 - INFO - Use pytorch device_name: cuda
2024-11-01 16:30:23,143 - INFO - Use pytorch device_name: cuda
2024-11-01 16:30:23,449 - INFO - Use pytorch device_name: cuda
2024-11-01 16:30:23,492 - INFO - Use pytorch device_name: cuda
2024-11-01 16:30:59,501 - INFO - Creating evaluators...
2024-11-01 16:30:59,623 - INFO - Creating evaluators...
2024-11-01 16:30:59,888 - INFO - Creating evaluators...
2024-11-01 16:31:00,073 - INFO - Creating evaluators...
2024-11-01 16:31:00,182 - INFO - Setting up trainer...
2024-11-01 16:31:00,186 - INFO - Added key: store_based_barrier_key:1 to store for rank: 2
2024-11-01 16:31:00,276 - INFO - Setting up trainer...
2024-11-01 16:31:00,280 - INFO - Added key: store_based_barrier_key:1 to store for rank: 0
2024-11-01 16:31:00,538 - INFO - Setting up trainer...
2024-11-01 16:31:00,542 - INFO - Added key: store_based_barrier_key:1 to store for rank: 3
2024-11-01 16:31:00,670 - INFO - Setting up trainer...
2024-11-01 16:31:00,674 - INFO - Added key: store_based_barrier_key:1 to store for rank: 1
2024-11-01 16:31:00,674 - INFO - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-11-01 16:31:00,676 - INFO - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-11-01 16:31:00,679 - INFO - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-11-01 16:31:00,682 - INFO - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2024-11-01 16:31:36,192 - WARNING - When using DistributedDataParallel (DDP), it is recommended to set `dataloader_drop_last=True` to avoid hanging issues with an uneven last batch. Setting `dataloader_drop_last=True`.
2024-11-01 16:31:36,199 - WARNING - When using DistributedDataParallel (DDP), it is recommended to set `dataloader_drop_last=True` to avoid hanging issues with an uneven last batch. Setting `dataloader_drop_last=True`.
2024-11-01 16:31:36,200 - WARNING - When using DistributedDataParallel (DDP), it is recommended to set `dataloader_drop_last=True` to avoid hanging issues with an uneven last batch. Setting `dataloader_drop_last=True`.
2024-11-01 16:31:36,207 - WARNING - When using DistributedDataParallel (DDP), it is recommended to set `dataloader_drop_last=True` to avoid hanging issues with an uneven last batch. Setting `dataloader_drop_last=True`.
2024-11-01 16:32:12,483 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2024-11-01 16:32:14,151 - INFO - Starting training...
2024-11-01 16:32:14,590 - INFO - Starting training...
2024-11-01 16:32:14,611 - INFO - Starting training...
2024-11-01 16:32:14,699 - INFO - Starting training...
2024-11-01 16:32:25,556 - ERROR - Training failed: Expected to mark a variable ready only once. This error is caused by one of the following reasons: 1) Use of a module parameter outside the `forward` function. Please make sure model parameters are not shared across multiple concurrent forward-backward passes. or try to use _set_static_graph() as a workaround if this module graph does not change during training loop.2) Reused parameters in multiple reentrant backward passes. For example, if you use multiple `checkpoint` functions to wrap the same part of your model, it would result in the same set of parameters been used by different reentrant backward passes multiple times, and hence marking a variable ready multiple times. DDP does not support such use cases in default. You can try to use _set_static_graph() as a workaround if your module graph does not change over iterations.
Parameter at index 195 has been marked as ready twice. This means that multiple autograd engine  hooks have fired for this particular parameter during this iteration. You can set the environment variable TORCH_DISTRIBUTED_DEBUG to either INFO or DETAIL to print parameter names for further debugging.
2024-11-01 16:32:25,560 - ERROR - Training failed: Expected to mark a variable ready only once. This error is caused by one of the following reasons: 1) Use of a module parameter outside the `forward` function. Please make sure model parameters are not shared across multiple concurrent forward-backward passes. or try to use _set_static_graph() as a workaround if this module graph does not change during training loop.2) Reused parameters in multiple reentrant backward passes. For example, if you use multiple `checkpoint` functions to wrap the same part of your model, it would result in the same set of parameters been used by different reentrant backward passes multiple times, and hence marking a variable ready multiple times. DDP does not support such use cases in default. You can try to use _set_static_graph() as a workaround if your module graph does not change over iterations.
Parameter at index 195 has been marked as ready twice. This means that multiple autograd engine  hooks have fired for this particular parameter during this iteration. You can set the environment variable TORCH_DISTRIBUTED_DEBUG to either INFO or DETAIL to print parameter names for further debugging.
2024-11-01 16:32:26,847 - ERROR - Training failed: Expected to mark a variable ready only once. This error is caused by one of the following reasons: 1) Use of a module parameter outside the `forward` function. Please make sure model parameters are not shared across multiple concurrent forward-backward passes. or try to use _set_static_graph() as a workaround if this module graph does not change during training loop.2) Reused parameters in multiple reentrant backward passes. For example, if you use multiple `checkpoint` functions to wrap the same part of your model, it would result in the same set of parameters been used by different reentrant backward passes multiple times, and hence marking a variable ready multiple times. DDP does not support such use cases in default. You can try to use _set_static_graph() as a workaround if your module graph does not change over iterations.
Parameter at index 195 has been marked as ready twice. This means that multiple autograd engine  hooks have fired for this particular parameter during this iteration. You can set the environment variable TORCH_DISTRIBUTED_DEBUG to either INFO or DETAIL to print parameter names for further debugging.
2024-11-01 16:32:27,572 - ERROR - Training failed: Expected to mark a variable ready only once. This error is caused by one of the following reasons: 1) Use of a module parameter outside the `forward` function. Please make sure model parameters are not shared across multiple concurrent forward-backward passes. or try to use _set_static_graph() as a workaround if this module graph does not change during training loop.2) Reused parameters in multiple reentrant backward passes. For example, if you use multiple `checkpoint` functions to wrap the same part of your model, it would result in the same set of parameters been used by different reentrant backward passes multiple times, and hence marking a variable ready multiple times. DDP does not support such use cases in default. You can try to use _set_static_graph() as a workaround if your module graph does not change over iterations.
Parameter at index 195 has been marked as ready twice. This means that multiple autograd engine  hooks have fired for this particular parameter during this iteration. You can set the environment variable TORCH_DISTRIBUTED_DEBUG to either INFO or DETAIL to print parameter names for further debugging.
2024-11-01 16:34:24,970 - INFO - Using device: cuda
2024-11-01 16:34:24,970 - INFO - Loading datasets...
2024-11-01 16:34:27,068 - INFO - Loaded 261772 corpus documents, 119456 queries
2024-11-01 16:34:27,068 - INFO - Preparing training dataset...
2024-11-01 16:34:29,866 - INFO - Setting up model and tokenizer...
2024-11-01 16:34:31,138 - INFO - Use pytorch device_name: cuda
2024-11-01 16:34:43,457 - INFO - Creating evaluators...
2024-11-01 16:34:44,018 - INFO - Setting up trainer...
2024-11-01 16:34:53,043 - WARNING - Currently using DataParallel (DP) for multi-gpu training, while DistributedDataParallel (DDP) is recommended for faster training. See https://sbert.net/docs/sentence_transformer/training/distributed.html for more information.
2024-11-01 16:35:02,117 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2024-11-01 16:35:03,809 - INFO - Starting training...
2024-11-01 16:47:03,039 - INFO - Information Retrieval Evaluation of the model on the dim_768 dataset (truncated to 768):
2024-11-01 17:00:53,436 - INFO - Using device: cuda:3
2024-11-01 17:00:53,437 - INFO - Loading datasets...
2024-11-01 17:00:55,429 - INFO - Loaded 261772 corpus documents, 119456 queries
2024-11-01 17:00:55,429 - INFO - Preparing training dataset...
2024-11-01 17:00:58,040 - INFO - Setting up model and tokenizer...
2024-11-01 17:00:59,249 - INFO - Use pytorch device_name: cuda
2024-11-01 17:01:09,326 - INFO - Creating evaluators...
2024-11-01 17:01:09,876 - INFO - Setting up trainer...
2024-11-01 17:01:18,951 - WARNING - Currently using DataParallel (DP) for multi-gpu training, while DistributedDataParallel (DDP) is recommended for faster training. See https://sbert.net/docs/sentence_transformer/training/distributed.html for more information.
2024-11-01 17:01:28,043 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2024-11-01 17:01:29,778 - INFO - Starting training...
2024-11-01 17:15:55,099 - INFO - Information Retrieval Evaluation of the model on the dim_768 dataset (truncated to 768):
2024-11-01 17:26:45,868 - INFO - Using device: cuda:3
2024-11-01 17:26:45,869 - INFO - Loading datasets...
2024-11-01 17:26:47,807 - INFO - Loaded 261772 corpus documents, 119456 queries
2024-11-01 17:26:47,807 - INFO - Preparing training dataset...
2024-11-01 17:26:50,388 - INFO - Setting up model and tokenizer...
2024-11-01 17:26:52,540 - INFO - Use pytorch device_name: cuda
2024-11-01 17:27:02,557 - INFO - Creating evaluators...
2024-11-01 17:27:03,044 - INFO - Setting up trainer...
2024-11-01 17:27:12,041 - WARNING - Currently using DataParallel (DP) for multi-gpu training, while DistributedDataParallel (DDP) is recommended for faster training. See https://sbert.net/docs/sentence_transformer/training/distributed.html for more information.
2024-11-01 17:27:21,160 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2024-11-01 17:27:22,858 - INFO - Starting training...
2024-11-01 17:34:03,368 - INFO - Using device: cuda:3
2024-11-01 17:34:03,369 - INFO - Loading datasets...
2024-11-01 17:34:05,252 - INFO - Loaded 261772 corpus documents, 119456 queries
2024-11-01 17:34:05,253 - INFO - Preparing training dataset...
2024-11-01 17:34:07,826 - INFO - Setting up model and tokenizer...
2024-11-01 17:34:10,004 - INFO - Use pytorch device_name: cuda
2024-11-01 17:34:19,928 - INFO - Creating evaluators...
2024-11-01 17:34:20,453 - INFO - Setting up trainer...
2024-11-01 17:34:29,468 - WARNING - Currently using DataParallel (DP) for multi-gpu training, while DistributedDataParallel (DDP) is recommended for faster training. See https://sbert.net/docs/sentence_transformer/training/distributed.html for more information.
2024-11-01 17:34:38,605 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2024-11-01 17:34:40,354 - INFO - Starting training...
2024-11-01 17:37:16,808 - INFO - Using device: cuda:3
2024-11-01 17:37:16,809 - INFO - Loading datasets...
2024-11-01 17:37:18,759 - INFO - Loaded 261772 corpus documents, 119456 queries
2024-11-01 17:37:18,759 - INFO - Preparing training dataset...
2024-11-01 17:37:21,640 - INFO - Setting up model and tokenizer...
2024-11-01 17:37:22,771 - INFO - Use pytorch device_name: cuda
2024-11-01 17:38:29,041 - INFO - Creating evaluators...
2024-11-01 17:38:29,663 - INFO - Setting up trainer...
2024-11-01 17:38:38,688 - WARNING - Currently using DataParallel (DP) for multi-gpu training, while DistributedDataParallel (DDP) is recommended for faster training. See https://sbert.net/docs/sentence_transformer/training/distributed.html for more information.
2024-11-01 17:38:47,804 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2024-11-01 17:38:49,587 - INFO - Starting training...
2024-11-01 17:51:13,190 - INFO - Information Retrieval Evaluation of the model on the dim_768 dataset (truncated to 768):
2024-11-01 18:22:52,988 - ERROR - Training failed: CUDA out of memory. Tried to allocate 22.25 GiB (GPU 0; 10.75 GiB total capacity; 2.51 GiB already allocated; 7.38 GiB free; 3.11 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2024-11-02 03:58:45,001 - INFO - Using device: cuda:3
2024-11-02 03:58:45,002 - INFO - Loading datasets...
2024-11-02 03:58:46,820 - INFO - Loaded 261772 corpus documents, 119456 queries
2024-11-02 03:58:46,821 - INFO - Preparing training dataset...
2024-11-02 03:58:49,323 - INFO - Setting up model and tokenizer...
2024-11-02 03:58:50,487 - INFO - Use pytorch device_name: cuda
2024-11-02 03:59:00,311 - INFO - Creating evaluators...
2024-11-02 03:59:00,838 - INFO - Setting up trainer...
2024-11-02 03:59:27,535 - WARNING - Currently using DataParallel (DP) for multi-gpu training, while DistributedDataParallel (DDP) is recommended for faster training. See https://sbert.net/docs/sentence_transformer/training/distributed.html for more information.
2024-11-02 03:59:45,454 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2024-11-02 03:59:51,362 - INFO - Starting training...
2024-11-02 04:11:37,592 - INFO - Information Retrieval Evaluation of the model on the dim_768 dataset (truncated to 768):
2024-11-02 04:16:00,303 - INFO - Using device: cuda
2024-11-02 04:16:00,303 - INFO - Loading datasets...
2024-11-02 04:16:02,214 - INFO - Loaded 261772 corpus documents, 119456 queries
2024-11-02 04:16:02,215 - INFO - Preparing training dataset...
2024-11-02 04:16:04,852 - INFO - Setting up model and tokenizer...
2024-11-02 04:16:06,030 - INFO - Use pytorch device_name: cuda
2024-11-02 04:16:15,682 - INFO - Creating evaluators...
2024-11-02 04:16:16,215 - INFO - Setting up trainer...
2024-11-02 04:16:25,224 - WARNING - Currently using DataParallel (DP) for multi-gpu training, while DistributedDataParallel (DDP) is recommended for faster training. See https://sbert.net/docs/sentence_transformer/training/distributed.html for more information.
2024-11-02 04:16:34,341 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2024-11-02 04:16:35,998 - INFO - Starting training...
2024-11-02 04:27:39,636 - INFO - Information Retrieval Evaluation of the model on the dim_768 dataset (truncated to 768):
2024-11-02 05:22:30,611 - INFO - Using device: cuda
2024-11-02 05:22:30,612 - INFO - Loading datasets...
2024-11-02 05:22:32,483 - INFO - Loaded 261772 corpus documents, 119456 queries
2024-11-02 05:22:32,484 - INFO - Preparing training dataset...
2024-11-02 05:22:35,093 - INFO - Setting up model and tokenizer...
2024-11-02 05:22:36,258 - INFO - Use pytorch device_name: cuda
2024-11-02 05:22:45,932 - INFO - Creating evaluators...
2024-11-02 05:22:46,481 - INFO - Setting up trainer...
2024-11-02 05:22:55,514 - WARNING - Currently using DataParallel (DP) for multi-gpu training, while DistributedDataParallel (DDP) is recommended for faster training. See https://sbert.net/docs/sentence_transformer/training/distributed.html for more information.
2024-11-02 05:23:04,617 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2024-11-02 05:23:06,215 - INFO - Starting training...
2024-11-02 05:35:23,131 - INFO - Information Retrieval Evaluation of the model on the dim_768 dataset (truncated to 768):
2024-11-02 06:07:20,860 - ERROR - Training failed: CUDA out of memory. Tried to allocate 22.25 GiB (GPU 0; 10.75 GiB total capacity; 2.51 GiB already allocated; 7.44 GiB free; 3.05 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2024-11-02 20:45:34,798 - INFO - Using device: cuda
2024-11-02 20:45:34,799 - INFO - Loading datasets...
2024-11-02 20:45:36,720 - INFO - Loaded 261772 corpus documents, 119456 queries
2024-11-02 20:45:36,720 - INFO - Preparing training dataset...
2024-11-02 20:45:39,355 - INFO - Setting up model and tokenizer...
2024-11-02 20:45:45,691 - INFO - Use pytorch device_name: cuda
2024-11-02 20:46:37,571 - INFO - Creating evaluators...
2024-11-02 20:46:38,309 - INFO - Setting up trainer...
2024-11-02 20:46:47,355 - WARNING - Currently using DataParallel (DP) for multi-gpu training, while DistributedDataParallel (DDP) is recommended for faster training. See https://sbert.net/docs/sentence_transformer/training/distributed.html for more information.
2024-11-02 20:46:56,462 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2024-11-02 20:47:11,593 - ERROR - Training failed: CUDA out of memory. Tried to allocate 770.00 MiB (GPU 0; 10.75 GiB total capacity; 7.87 GiB already allocated; 217.56 MiB free; 7.97 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2024-11-02 21:13:32,320 - INFO - Using device: cuda
2024-11-02 21:13:32,321 - INFO - Loading datasets...
2024-11-02 21:13:34,241 - INFO - Loaded 261772 corpus documents, 119456 queries
2024-11-02 21:13:34,241 - INFO - Preparing training dataset...
2024-11-02 21:13:36,850 - INFO - Setting up model and tokenizer...
2024-11-02 21:13:38,541 - INFO - Use pytorch device_name: cuda
2024-11-02 21:13:48,239 - INFO - Creating evaluators...
2024-11-02 21:13:48,810 - INFO - Setting up trainer...
2024-11-02 21:13:57,824 - WARNING - Currently using DataParallel (DP) for multi-gpu training, while DistributedDataParallel (DDP) is recommended for faster training. See https://sbert.net/docs/sentence_transformer/training/distributed.html for more information.
2024-11-02 21:14:06,907 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2024-11-02 21:26:39,577 - INFO - Using device: cuda
2024-11-02 21:26:39,578 - INFO - Loading datasets...
2024-11-02 21:26:41,442 - INFO - Loaded 261772 corpus documents, 119456 queries
2024-11-02 21:26:41,442 - INFO - Preparing training dataset...
2024-11-02 21:26:44,020 - INFO - Setting up model and tokenizer...
2024-11-02 21:26:45,724 - INFO - Use pytorch device_name: cuda
2024-11-02 21:26:55,429 - INFO - Creating evaluators...
2024-11-02 21:26:55,946 - INFO - Setting up trainer...
2024-11-02 21:27:04,982 - WARNING - Currently using DataParallel (DP) for multi-gpu training, while DistributedDataParallel (DDP) is recommended for faster training. See https://sbert.net/docs/sentence_transformer/training/distributed.html for more information.
2024-11-02 21:27:14,019 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
