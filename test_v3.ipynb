{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 10000/10000 [00:00<00:00, 623280.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from src.preprocessor.utils.dataset_level import read_pickle, prepare_training_dataset, read_json\n",
    "from itertools import islice\n",
    "\n",
    "corpus = read_pickle('/home/thiendc/projects/legal_retrieval/data/processed/corpus.pkl')\n",
    "corpus = {i: j.replace(\"\\xa0\", \"\") for i, j in corpus.items()}\n",
    "\n",
    "queries = read_pickle('/home/thiendc/projects/legal_retrieval/data/processed/queries.pkl')\n",
    "relevant_docs = read_pickle('/home/thiendc/projects/legal_retrieval/data/processed/relevant_docs.pkl')\n",
    "relevant_docs  = dict(islice(relevant_docs.items(), 10000))\n",
    "train_dataset = prepare_training_dataset(queries, corpus, relevant_docs)\n",
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 289 new tokens to the vocabulary\n"
     ]
    }
   ],
   "source": [
    "# from sentence_transformers import SentenceTransformer, models\n",
    "# from transformers import AutoTokenizer, AutoModel\n",
    "# import os\n",
    "\n",
    "# def setup_embedding_model(model_name, new_tokens=None):\n",
    "#     \"\"\"\n",
    "#     Set up a sentence transformer model with proper tokenizer handling\n",
    "    \n",
    "#     Args:\n",
    "#         model_name (str): HuggingFace model name/path\n",
    "#         new_tokens (list): Optional list of new tokens to add to vocabulary\n",
    "    \n",
    "#     Returns:\n",
    "#         SentenceTransformer: Properly configured sentence transformer model\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Set up tokenizer and model in SentenceTransformer\n",
    "#     word_embedding_model = models.Transformer(model_name)\n",
    "#     tokenizer = word_embedding_model.tokenizer\n",
    "    \n",
    "#     # Add new tokens if provided\n",
    "#     if new_tokens is not None:\n",
    "#         tokenizer.add_tokens(new_tokens, special_tokens=False)\n",
    "#         word_embedding_model.auto_model.resize_token_embeddings(len(tokenizer))\n",
    "    \n",
    "#     # Create the SentenceTransformer model with the word embedding model\n",
    "#     sentence_model = SentenceTransformer(modules=[word_embedding_model])\n",
    "    \n",
    "#     return sentence_model\n",
    "\n",
    "# # Load new tokens and setup model\n",
    "# new_tokens = read_json('./src/preprocessor/vocab/data/update_vocab_v1.json') \n",
    "# tokenizer = AutoTokenizer.from_pretrained('intfloat/e5-base-v2')\n",
    "# tokenizer.add_tokens(new_tokens, special_tokens=False)\n",
    "\n",
    "# # 2. Create the base model\n",
    "# base_model = AutoModel.from_pretrained('intfloat/e5-base-v2')\n",
    "# base_model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# # 3. Create word embedding model using sentence-transformers format\n",
    "# word_embedding_model = models.Transformer(\n",
    "#     model_name_or_path='intfloat/e5-base-v2',\n",
    "#     tokenizer_name_or_path='intfloat/e5-base-v2'\n",
    "# )\n",
    "\n",
    "# # 4. Create pooling model\n",
    "# pooling_model = models.Pooling(\n",
    "#     word_embedding_model.get_word_embedding_dimension(),\n",
    "#     pooling_mode_mean_tokens=True,\n",
    "#     pooling_mode_cls_token=False,\n",
    "#     pooling_mode_max_tokens=False\n",
    "# )\n",
    "\n",
    "# # 5. Create the full SentenceTransformer model\n",
    "# model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "# # Now you can use model directly in SentenceTransformerTrainer\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, models\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "def setup_embedding_model(model_name, new_tokens=None):\n",
    "    \"\"\"\n",
    "    Set up a sentence transformer model with proper tokenizer handling and pooling\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): HuggingFace model name/path\n",
    "        new_tokens (list): Optional list of new tokens to add to vocabulary\n",
    "    \n",
    "    Returns:\n",
    "        SentenceTransformer: Properly configured sentence transformer model\n",
    "    \"\"\"\n",
    "    # Set up word embedding model\n",
    "    word_embedding_model = models.Transformer(model_name, max_seq_length= 512)\n",
    "    tokenizer = word_embedding_model.tokenizer\n",
    "    \n",
    "    # Add new tokens if provided\n",
    "    if new_tokens is not None:\n",
    "        num_added_tokens = tokenizer.add_tokens(new_tokens, special_tokens=False)\n",
    "        print(f\"Added {num_added_tokens} new tokens to the vocabulary\")\n",
    "        # Resize model embeddings to account for new tokens\n",
    "        word_embedding_model.auto_model.resize_token_embeddings(len(tokenizer))\n",
    "    \n",
    "    # Create pooling model\n",
    "    pooling_model = models.Pooling(\n",
    "        word_embedding_model.get_word_embedding_dimension(),\n",
    "        pooling_mode_mean_tokens=True,\n",
    "        pooling_mode_cls_token=False,\n",
    "        pooling_mode_max_tokens=False\n",
    "    )\n",
    "    \n",
    "    # Create the full SentenceTransformer model\n",
    "    sentence_model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "    \n",
    "    return sentence_model, tokenizer\n",
    "\n",
    "# Sử dụng hàm:\n",
    "# 1. Load new tokens\n",
    "new_tokens = read_json('./src/preprocessor/vocab/data/update_vocab_v2.json')\n",
    "\n",
    "# 2. Setup model với vocab mới\n",
    "model, _ = setup_embedding_model('dangvantuan/vietnamese-embedding', new_tokens= new_tokens)\n",
    "# model = SentenceTransformer(\"intfloat/multilingual-e5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import (\n",
    "    InformationRetrievalEvaluator,\n",
    "    SequentialEvaluator,\n",
    ")\n",
    "from sentence_transformers.util import cos_sim as consine\n",
    "\n",
    "\n",
    "matryoshka_dimensions = [768, 512, 256] # Important: large to small\n",
    "matryoshka_evaluators = []\n",
    "# Iterate over the different dimensions\n",
    "for dim in matryoshka_dimensions:\n",
    "    ir_evaluator = InformationRetrievalEvaluator(\n",
    "        queries=queries,\n",
    "        corpus=corpus,\n",
    "        relevant_docs=relevant_docs,\n",
    "        name=f\"dim_{dim}\",\n",
    "        truncate_dim=dim,  # Truncate the embeddings to a certain dimension\n",
    "        score_functions={\"cosine\": consine},\n",
    "    )\n",
    "    matryoshka_evaluators.append(ir_evaluator)\n",
    "\n",
    "# Create a sequential evaluator\n",
    "evaluator = SequentialEvaluator(matryoshka_evaluators)\n",
    "# evaluator = InformationRetrievalEvaluator(\n",
    "#         queries=queries,\n",
    "#         corpus=corpus,\n",
    "#         relevant_docs=relevant_docs,\n",
    "#         name=f\"dim_768\",\n",
    "#         truncate_dim= 768,  # Truncate the embeddings to a certain dimension\n",
    "#         score_functions={\"cosine\": consine},\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sentence_transformers.losses import MatryoshkaLoss, MultipleNegativesRankingLoss\n",
    "\n",
    "inner_train_loss = MultipleNegativesRankingLoss(model)\n",
    "train_loss = MatryoshkaLoss(\n",
    "    model, inner_train_loss, matryoshka_dims=matryoshka_dimensions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Currently using DataParallel (DP) for multi-gpu training, while DistributedDataParallel (DDP) is recommended for faster training. See https://sbert.net/docs/sentence_transformer/training/distributed.html for more information.\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "from contextlib import contextmanager\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "from sentence_transformers import SentenceTransformerTrainer, SentenceTransformerTrainingArguments\n",
    "\n",
    "@contextmanager\n",
    "def track_memory():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    yield\n",
    "    print(f\"Peak memory: {torch.cuda.max_memory_allocated() / 1e9:.2f} GB\")\n",
    "\n",
    "# Custom trainer với memory management\n",
    "class MemoryEfficientTrainer(SentenceTransformerTrainer):\n",
    "    def training_step(self, *args, **kwargs):\n",
    "        loss = super().training_step(*args, **kwargs)\n",
    "        \n",
    "        # Dọn memory Python và CUDA cache sau mỗi step\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        # Dọn memory sau mỗi epoch\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        super().on_epoch_end()\n",
    "\n",
    "# Training arguments\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"legal_finetuning_v2\",\n",
    "    num_train_epochs = 10,\n",
    "    per_device_train_batch_size= 4,  # Giảm batch size             \n",
    "    gradient_accumulation_steps= 8,  # Tăng gradient accumulation            \n",
    "    per_device_eval_batch_size= 8,\n",
    "    gradient_checkpointing=True,\n",
    "    warmup_ratio=0.15,\n",
    "    learning_rate= 2e-5,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    optim=\"adamw_torch_fused\",\n",
    "    fp16=True,\n",
    "    batch_sampler=BatchSamplers.NO_DUPLICATES,\n",
    "    eval_strategy=\"steps\",\n",
    "    save_steps= 50,\n",
    "    logging_steps = 5,\n",
    "    save_total_limit = 5,\n",
    "    load_best_model_at_end=True,\n",
    "    max_grad_norm=0.5,\n",
    "    metric_for_best_model=\"eval_dim_768_cosine_ndcg@10\",\n",
    "    ddp_find_unused_parameters=False,\n",
    "    dataloader_num_workers = 40\n",
    ")\n",
    "\n",
    "# Khởi tạo trainer với custom class\n",
    "trainer = MemoryEfficientTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    loss=train_loss,\n",
    "    evaluator=evaluator,\n",
    ")\n",
    "\n",
    "# Dọn cache trước khi training\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = SentenceTransformerTrainer(\n",
    "#     model=model,\n",
    "#     args=args,\n",
    "#     train_dataset= train_dataset,\n",
    "#     loss=train_loss,\n",
    "#     evaluator=evaluator,\n",
    "# )\n",
    "# torch.cuda.empty_cache()\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mthiendc3005\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9acafc9ce23e4a809ac55e0c558be9b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112966856712269, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/thiendc/projects/legal_retrieval/wandb/run-20241103_063700-0wfnhiz5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thiendc3005/sentence-transformers/runs/0wfnhiz5' target=\"_blank\">legal_finetuning_v2</a></strong> to <a href='https://wandb.ai/thiendc3005/sentence-transformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thiendc3005/sentence-transformers' target=\"_blank\">https://wandb.ai/thiendc3005/sentence-transformers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thiendc3005/sentence-transformers/runs/0wfnhiz5' target=\"_blank\">https://wandb.ai/thiendc3005/sentence-transformers/runs/0wfnhiz5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 16/110 1:19:05 < 8:51:05, 0.00 it/s, Epoch 1.06/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Dim 768 Cosine Accuracy@1</th>\n",
       "      <th>Dim 768 Cosine Accuracy@3</th>\n",
       "      <th>Dim 768 Cosine Accuracy@5</th>\n",
       "      <th>Dim 768 Cosine Accuracy@10</th>\n",
       "      <th>Dim 768 Cosine Precision@1</th>\n",
       "      <th>Dim 768 Cosine Precision@3</th>\n",
       "      <th>Dim 768 Cosine Precision@5</th>\n",
       "      <th>Dim 768 Cosine Precision@10</th>\n",
       "      <th>Dim 768 Cosine Recall@1</th>\n",
       "      <th>Dim 768 Cosine Recall@3</th>\n",
       "      <th>Dim 768 Cosine Recall@5</th>\n",
       "      <th>Dim 768 Cosine Recall@10</th>\n",
       "      <th>Dim 768 Cosine Ndcg@10</th>\n",
       "      <th>Dim 768 Cosine Mrr@10</th>\n",
       "      <th>Dim 768 Cosine Map@100</th>\n",
       "      <th>Dim 512 Cosine Accuracy@1</th>\n",
       "      <th>Dim 512 Cosine Accuracy@3</th>\n",
       "      <th>Dim 512 Cosine Accuracy@5</th>\n",
       "      <th>Dim 512 Cosine Accuracy@10</th>\n",
       "      <th>Dim 512 Cosine Precision@1</th>\n",
       "      <th>Dim 512 Cosine Precision@3</th>\n",
       "      <th>Dim 512 Cosine Precision@5</th>\n",
       "      <th>Dim 512 Cosine Precision@10</th>\n",
       "      <th>Dim 512 Cosine Recall@1</th>\n",
       "      <th>Dim 512 Cosine Recall@3</th>\n",
       "      <th>Dim 512 Cosine Recall@5</th>\n",
       "      <th>Dim 512 Cosine Recall@10</th>\n",
       "      <th>Dim 512 Cosine Ndcg@10</th>\n",
       "      <th>Dim 512 Cosine Mrr@10</th>\n",
       "      <th>Dim 512 Cosine Map@100</th>\n",
       "      <th>Dim 256 Cosine Accuracy@1</th>\n",
       "      <th>Dim 256 Cosine Accuracy@3</th>\n",
       "      <th>Dim 256 Cosine Accuracy@5</th>\n",
       "      <th>Dim 256 Cosine Accuracy@10</th>\n",
       "      <th>Dim 256 Cosine Precision@1</th>\n",
       "      <th>Dim 256 Cosine Precision@3</th>\n",
       "      <th>Dim 256 Cosine Precision@5</th>\n",
       "      <th>Dim 256 Cosine Precision@10</th>\n",
       "      <th>Dim 256 Cosine Recall@1</th>\n",
       "      <th>Dim 256 Cosine Recall@3</th>\n",
       "      <th>Dim 256 Cosine Recall@5</th>\n",
       "      <th>Dim 256 Cosine Recall@10</th>\n",
       "      <th>Dim 256 Cosine Ndcg@10</th>\n",
       "      <th>Dim 256 Cosine Mrr@10</th>\n",
       "      <th>Dim 256 Cosine Map@100</th>\n",
       "      <th>Sequential Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.249600</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>0.009141</td>\n",
       "      <td>0.009987</td>\n",
       "      <td>0.010606</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>0.003064</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>0.001071</td>\n",
       "      <td>0.006233</td>\n",
       "      <td>0.008032</td>\n",
       "      <td>0.008759</td>\n",
       "      <td>0.009289</td>\n",
       "      <td>0.008006</td>\n",
       "      <td>0.008227</td>\n",
       "      <td>0.007329</td>\n",
       "      <td>0.006806</td>\n",
       "      <td>0.009058</td>\n",
       "      <td>0.009836</td>\n",
       "      <td>0.010481</td>\n",
       "      <td>0.006806</td>\n",
       "      <td>0.003033</td>\n",
       "      <td>0.001982</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>0.006064</td>\n",
       "      <td>0.007955</td>\n",
       "      <td>0.008617</td>\n",
       "      <td>0.009171</td>\n",
       "      <td>0.007873</td>\n",
       "      <td>0.008075</td>\n",
       "      <td>0.007196</td>\n",
       "      <td>0.006563</td>\n",
       "      <td>0.008882</td>\n",
       "      <td>0.009619</td>\n",
       "      <td>0.010313</td>\n",
       "      <td>0.006563</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.005840</td>\n",
       "      <td>0.007854</td>\n",
       "      <td>0.008471</td>\n",
       "      <td>0.009044</td>\n",
       "      <td>0.007709</td>\n",
       "      <td>0.007876</td>\n",
       "      <td>0.007032</td>\n",
       "      <td>0.007032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.959400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.007425</td>\n",
       "      <td>0.009702</td>\n",
       "      <td>0.010439</td>\n",
       "      <td>0.010908</td>\n",
       "      <td>0.007425</td>\n",
       "      <td>0.003254</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.001101</td>\n",
       "      <td>0.006619</td>\n",
       "      <td>0.008542</td>\n",
       "      <td>0.009180</td>\n",
       "      <td>0.009549</td>\n",
       "      <td>0.008407</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.007747</td>\n",
       "      <td>0.007333</td>\n",
       "      <td>0.009627</td>\n",
       "      <td>0.010347</td>\n",
       "      <td>0.010841</td>\n",
       "      <td>0.007333</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.006528</td>\n",
       "      <td>0.008484</td>\n",
       "      <td>0.009098</td>\n",
       "      <td>0.009496</td>\n",
       "      <td>0.008321</td>\n",
       "      <td>0.008598</td>\n",
       "      <td>0.007657</td>\n",
       "      <td>0.007283</td>\n",
       "      <td>0.009334</td>\n",
       "      <td>0.010062</td>\n",
       "      <td>0.010724</td>\n",
       "      <td>0.007283</td>\n",
       "      <td>0.003128</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>0.006495</td>\n",
       "      <td>0.008230</td>\n",
       "      <td>0.008883</td>\n",
       "      <td>0.009408</td>\n",
       "      <td>0.008217</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.007564</td>\n",
       "      <td>0.007564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Training với memory tracking\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m track_memory():\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Dọn memory sau khi training xong\u001b[39;00m\n\u001b[1;32m      6\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n",
      "File \u001b[0;32m~/projects/.thienenv/lib/python3.10/site-packages/transformers/trainer.py:2052\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2052\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/.thienenv/lib/python3.10/site-packages/transformers/trainer.py:2467\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2464\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   2465\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2467\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2468\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2469\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/projects/.thienenv/lib/python3.10/site-packages/transformers/trainer.py:2915\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2913\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n\u001b[0;32m-> 2915\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[1;32m   2918\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_checkpoint(model, trial, metrics\u001b[38;5;241m=\u001b[39mmetrics)\n",
      "File \u001b[0;32m~/projects/.thienenv/lib/python3.10/site-packages/transformers/trainer.py:2872\u001b[0m, in \u001b[0;36mTrainer._evaluate\u001b[0;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[1;32m   2871\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, ignore_keys_for_eval, skip_scheduler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m-> 2872\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2873\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2875\u001b[0m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/.thienenv/lib/python3.10/site-packages/sentence_transformers/trainer.py:401\u001b[0m, in \u001b[0;36mSentenceTransformerTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(eval_dataset, DatasetDict) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    400\u001b[0m     eval_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_dataset_name_column(eval_dataset)\n\u001b[0;32m--> 401\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/.thienenv/lib/python3.10/site-packages/transformers/trainer.py:3868\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3865\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3867\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3868\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3869\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3871\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3872\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3874\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3875\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3876\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3878\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/projects/.thienenv/lib/python3.10/site-packages/sentence_transformers/trainer.py:433\u001b[0m, in \u001b[0;36mSentenceTransformerTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m nullcontext() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_local_process_zero() \u001b[38;5;28;01melse\u001b[39;00m disable_logging(logging\u001b[38;5;241m.\u001b[39mINFO):\n\u001b[0;32m--> 433\u001b[0m     evaluator_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(evaluator_metrics, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    435\u001b[0m     evaluator_metrics \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluator\u001b[39m\u001b[38;5;124m\"\u001b[39m: evaluator_metrics}\n",
      "File \u001b[0;32m~/projects/.thienenv/lib/python3.10/site-packages/sentence_transformers/evaluation/SequentialEvaluator.py:46\u001b[0m, in \u001b[0;36mSequentialEvaluator.__call__\u001b[0;34m(self, model, output_path, epoch, steps)\u001b[0m\n\u001b[1;32m     44\u001b[0m scores \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m evaluator_idx, evaluator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluators):\n\u001b[0;32m---> 46\u001b[0m     evaluation \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(evaluation, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m     49\u001b[0m         scores\u001b[38;5;241m.\u001b[39mappend(evaluation)\n",
      "File \u001b[0;32m~/projects/.thienenv/lib/python3.10/site-packages/sentence_transformers/evaluation/InformationRetrievalEvaluator.py:237\u001b[0m, in \u001b[0;36mInformationRetrievalEvaluator.__call__\u001b[0;34m(self, model, output_path, epoch, steps, *args, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m     out_txt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (truncated to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtruncate_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    235\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInformation Retrieval Evaluation of the model on the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dataset\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_txt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 237\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;66;03m# Write results to disc\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_csv:\n",
      "File \u001b[0;32m~/projects/.thienenv/lib/python3.10/site-packages/sentence_transformers/evaluation/InformationRetrievalEvaluator.py:308\u001b[0m, in \u001b[0;36mInformationRetrievalEvaluator.compute_metrices\u001b[0;34m(self, model, corpus_model, corpus_embeddings)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;66;03m# Compute embedding for the queries\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m nullcontext() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtruncate_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m model\u001b[38;5;241m.\u001b[39mtruncate_sentence_embeddings(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtruncate_dim):\n\u001b[0;32m--> 308\u001b[0m     query_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_prompt_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m queries_result_list \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_functions:\n",
      "File \u001b[0;32m~/projects/.thienenv/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:617\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    608\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m    609\u001b[0m             features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m    610\u001b[0m                 (\n\u001b[1;32m    611\u001b[0m                     features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    614\u001b[0m                 \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    615\u001b[0m             )\n\u001b[0;32m--> 617\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    618\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate(extra_features)\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/projects/.thienenv/lib/python3.10/site-packages/sentence_transformers/util.py:1067\u001b[0m, in \u001b[0;36mbatch_to_device\u001b[0;34m(batch, target_device)\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch[key], Tensor):\n\u001b[0;32m-> 1067\u001b[0m         batch[key] \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_device\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training với memory tracking\n",
    "with track_memory():\n",
    "    trainer.train()\n",
    "\n",
    "# Dọn memory sau khi training xong\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "Your token has been saved in your configured git credential helpers (store).\n",
      "Your token has been saved to /home/thiendc/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588905a06ed849c6bdf96afe7df4e99d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/559M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/Tnt3o5/test_embedding_model/commit/a6177571d2c5535081604dbd0f8326683b8604f0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from huggingface_hub import login\n",
    "# login(token=\"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\", add_to_git_credential=True)\n",
    "# trainer.model.push_to_hub(\"test_embedding_model_v2\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
