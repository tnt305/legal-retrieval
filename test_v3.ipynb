{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing queries: 100%|██████████| 119456/119456 [00:00<00:00, 796526.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lỗi KeyError: '145694' - Bỏ qua query_id: 75151, doc_id: 145694\n",
      "Lỗi KeyError: '156611' - Bỏ qua query_id: 154595, doc_id: 156611\n",
      "Lỗi KeyError: '78193' - Bỏ qua query_id: 14988, doc_id: 78193\n",
      "Lỗi KeyError: '121737' - Bỏ qua query_id: 53808, doc_id: 121737\n",
      "Lỗi KeyError: '104474' - Bỏ qua query_id: 175694, doc_id: 104474\n",
      "Lỗi KeyError: '6115' - Bỏ qua query_id: 157856, doc_id: 6115\n",
      "Lỗi KeyError: '61435' - Bỏ qua query_id: 10, doc_id: 61435\n",
      "Lỗi KeyError: '19478' - Bỏ qua query_id: 123964, doc_id: 19478\n",
      "Lỗi KeyError: '215415' - Bỏ qua query_id: 137473, doc_id: 215415\n",
      "Lỗi KeyError: '111348' - Bỏ qua query_id: 44532, doc_id: 111348\n",
      "Lỗi KeyError: '120847' - Bỏ qua query_id: 108391, doc_id: 120847\n",
      "Lỗi KeyError: '193554' - Bỏ qua query_id: 117949, doc_id: 193554\n",
      "Lỗi KeyError: '85594' - Bỏ qua query_id: 115534, doc_id: 85594\n",
      "Lỗi KeyError: '78193' - Bỏ qua query_id: 154692, doc_id: 78193\n",
      "Lỗi KeyError: '19478' - Bỏ qua query_id: 172715, doc_id: 19478\n",
      "Lỗi KeyError: '77193' - Bỏ qua query_id: 15895, doc_id: 77193\n",
      "Lỗi KeyError: '19478' - Bỏ qua query_id: 174545, doc_id: 19478\n",
      "Lỗi KeyError: '200902' - Bỏ qua query_id: 124496, doc_id: 200902\n",
      "Lỗi KeyError: '65225' - Bỏ qua query_id: 3409, doc_id: 65225\n",
      "Lỗi KeyError: '151654' - Bỏ qua query_id: 80485, doc_id: 151654\n",
      "Lỗi KeyError: '128349' - Bỏ qua query_id: 59714, doc_id: 128349\n",
      "Lỗi KeyError: '121737' - Bỏ qua query_id: 138673, doc_id: 121737\n",
      "Lỗi KeyError: '156611' - Bỏ qua query_id: 84912, doc_id: 156611\n",
      "Lỗi KeyError: '105758' - Bỏ qua query_id: 39536, doc_id: 105758\n",
      "Lỗi KeyError: '109734' - Bỏ qua query_id: 43095, doc_id: 109734\n",
      "Lỗi KeyError: '110081' - Bỏ qua query_id: 43406, doc_id: 110081\n",
      "Lỗi KeyError: '104474' - Bỏ qua query_id: 38390, doc_id: 104474\n",
      "Lỗi KeyError: '149611' - Bỏ qua query_id: 78665, doc_id: 149611\n",
      "Lỗi KeyError: '105758' - Bỏ qua query_id: 74128, doc_id: 105758\n",
      "Lỗi KeyError: '85594' - Bỏ qua query_id: 149989, doc_id: 85594\n",
      "Lỗi KeyError: '128349' - Bỏ qua query_id: 163369, doc_id: 128349\n",
      "Lỗi KeyError: '104474' - Bỏ qua query_id: 153367, doc_id: 104474\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from src.preprocessor.utils.dataset_level import prepare_training_dataset\n",
    "with open('./data/processed/queries.pkl', 'rb') as f:\n",
    "    queries = pickle.load(f)\n",
    "with open('./data/processed/corpus.pkl', 'rb') as f:\n",
    "    corpus = pickle.load(f)\n",
    "with open('./data/processed/relevant_docs.pkl', 'rb') as f:\n",
    "    relevant_docs = pickle.load(f)\n",
    "\n",
    "pairs = prepare_training_dataset(queries, corpus, relevant_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.evaluation import (\n",
    "    InformationRetrievalEvaluator,\n",
    "    SequentialEvaluator,\n",
    ")\n",
    "from sentence_transformers.util import cos_sim as consine\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "model = SentenceTransformer(\"NghiemAbe/Vi-Legal-Bi-Encoder-v2\")\n",
    "matryoshka_dimensions = [768, 512, 256, 128, 64] # Important: large to small\n",
    "matryoshka_evaluators = []\n",
    "# Iterate over the different dimensions\n",
    "for dim in matryoshka_dimensions:\n",
    "    ir_evaluator = InformationRetrievalEvaluator(\n",
    "        queries=queries,\n",
    "        corpus=corpus,\n",
    "        relevant_docs=relevant_docs,\n",
    "        name=f\"dim_{dim}\",\n",
    "        truncate_dim=dim,  # Truncate the embeddings to a certain dimension\n",
    "        score_functions={\"cosine\": consine},\n",
    "    )\n",
    "    matryoshka_evaluators.append(ir_evaluator)\n",
    "\n",
    "# Create a sequential evaluator\n",
    "evaluator = SequentialEvaluator(matryoshka_evaluators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.losses import MatryoshkaLoss, MultipleNegativesRankingLoss\n",
    "\n",
    "matryoshka_dimensions = [768, 512, 256, 128, 64]  # Important: large to small\n",
    "inner_train_loss = MultipleNegativesRankingLoss(model)\n",
    "train_loss = MatryoshkaLoss(\n",
    "    model, inner_train_loss, matryoshka_dims=matryoshka_dimensions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mthiendc3005\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/thiendc/.netrc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "289aa3d7e9c14ceeaa6a1e13abd45f48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112952222012812, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/thiendc/projects/legal_retrieval/wandb/run-20241030_170241-yip3qnbz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thiendc3005/sentence_sim/runs/yip3qnbz' target=\"_blank\">experiment-v1</a></strong> to <a href='https://wandb.ai/thiendc3005/sentence_sim' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thiendc3005/sentence_sim' target=\"_blank\">https://wandb.ai/thiendc3005/sentence_sim</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thiendc3005/sentence_sim/runs/yip3qnbz' target=\"_blank\">https://wandb.ai/thiendc3005/sentence_sim/runs/yip3qnbz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/thiendc3005/sentence_sim/runs/yip3qnbz?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f6ed8de0a60>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login(key=\"02ba155e26496a78f062f683274330566fefe94c\")\n",
    "wandb.init(\n",
    "    project=\"sentence_sim\",  # Đặt tên project phù hợp\n",
    "    name=\"experiment-v1\",\n",
    "    config={\n",
    "        # Training hyperparameters\n",
    "        \"model_name\": \"base_model_name\",  # tên model base bạn dùng\n",
    "        \"learning_rate\": 2e-5,\n",
    "        \"epochs\": 50,\n",
    "        \"per_device_batch_size\": 4,\n",
    "        \"effective_batch_size\": 4 * 8 * 4,  # batch_size * gradient_accum * num_gpus\n",
    "        \"warmup_ratio\": 0.1,\n",
    "        \"optimizer\": \"adamw_torch_fused\",\n",
    "        \n",
    "        # Model architecture\n",
    "        \"embedding_dim\": 768,  # dựa trên metric của bạn\n",
    "        \n",
    "        # Dataset info\n",
    "        \"train_dataset_size\": None,  # số lượng training samples\n",
    "        \"eval_dataset_size\": None,   # số lượng validation samples\n",
    "        \n",
    "        # Hardware config\n",
    "        \"num_gpus\": 4,\n",
    "        \"gpu_type\": \"RTX 2080Ti\",\n",
    "        \"gradient_checkpointing\": True,\n",
    "        \"fp16\": True,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SentenceTransformerTrainingArguments.__init__() got an unexpected keyword argument 'early_stopping_patience'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining_args\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BatchSamplers\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# torch.distributed.init_process_group(backend='nccl')\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# define training arguments\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[43mSentenceTransformerTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_dir\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 2080Ti has 11GB VRAM, reduced batch size for multi-GPU training\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;66;43;03m# reduced from 8 to 4\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_accumulation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;66;43;03m# increased to maintain effective batch size\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_checkpointing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;66;43;03m# enabled to save memory\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarmup_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr_scheduler_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcosine\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madamw_torch_fused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                       \u001b[49m\u001b[38;5;66;43;03m# changed from fused to regular adamw for better compatibility\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfp16\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m                                 \u001b[49m\u001b[38;5;66;43;03m# keep fp16 for memory efficiency\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_sampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBatchSamplers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNO_DUPLICATES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msteps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogging_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_total_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_best_model_at_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_for_best_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_dim_768_cosine_ndcg@10\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_patience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Thêm wandb config\u001b[39;49;00m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreport_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwandb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# Enable wandb logging\u001b[39;49;00m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# Sử dụng tên run từ wandb\u001b[39;49;00m\n\u001b[1;32m     31\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformerTrainer\n\u001b[1;32m     34\u001b[0m trainer \u001b[38;5;241m=\u001b[39m SentenceTransformerTrainer(\n\u001b[1;32m     35\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     36\u001b[0m     args\u001b[38;5;241m=\u001b[39margs,  \u001b[38;5;66;03m# training arguments\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m     evaluator\u001b[38;5;241m=\u001b[39mevaluator,\n\u001b[1;32m     40\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: SentenceTransformerTrainingArguments.__init__() got an unexpected keyword argument 'early_stopping_patience'"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformerTrainingArguments\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "\n",
    "# torch.distributed.init_process_group(backend='nccl')\n",
    "# define training arguments\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"output_dir\",\n",
    "    num_train_epochs=50,\n",
    "    # 2080Ti has 11GB VRAM, reduced batch size for multi-GPU training\n",
    "    per_device_train_batch_size=4,             # reduced from 8 to 4\n",
    "    gradient_accumulation_steps=8,             # increased to maintain effective batch size\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_checkpointing=True,               # enabled to save memory\n",
    "    warmup_ratio=0.1,\n",
    "    learning_rate=2e-5,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    optim=\"adamw_torch_fused\",                       # changed from fused to regular adamw for better compatibility\n",
    "    fp16=True,                                 # keep fp16 for memory efficiency\n",
    "    batch_sampler=BatchSamplers.NO_DUPLICATES,\n",
    "    eval_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    logging_steps=10,\n",
    "    save_total_limit=3,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_dim_768_cosine_ndcg@10\",\n",
    "    # Thêm wandb config\n",
    "    report_to=[\"wandb\"],          # Enable wandb logging\n",
    "    run_name=wandb.run.name      # Sử dụng tên run từ wandb\n",
    ")\n",
    "\n",
    "from sentence_transformers import SentenceTransformerTrainer\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=args,  # training arguments\n",
    "    train_dataset=pairs,\n",
    "    loss=train_loss,\n",
    "    evaluator=evaluator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
